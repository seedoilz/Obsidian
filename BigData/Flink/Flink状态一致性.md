---
aliases:
  - Flink Exactly-Once
title: Flink状态一致性
date created: 2024-09-21 22:09:00
date modified: 2024-09-21 22:09:50
tags:
  - code/big-data
---

## Flink状态一致性
![image.png](https://typora-tes.oss-cn-shanghai.aliyuncs.com/picgo/20240921220315.png)
- 有状态的流处理，内部每个算子任务都可以有自己的状态
- 对于流处理器内部来说，所谓的状态一致性，其实就是我们所说的计算结果要保证准确。
- 一条数据不应该丢失，也不应该重复计算
- 在遇到故障时可以恢复状态，恢复以后的重新计算，结果应该也是完全正确的。 

### 状态一致性分类
#### AT-MOST-ONCE（最多一次）
当任务故障时，最简单的做法是什么都不干，既不恢复丢失的状态，也不重播丢失的数据。At-most-once 语义的含义是最多处理一次事件。

#### AT-LEAST-ONCE（至少一次）
在大多数的真实应用场景，我们希望不丢失事件。这种类型的保障称为 at least-once，意思是所有的事件都得到了处理，而一些事件还可能被处理多次。

#### EXACTLY-ONCE（精确一次）
恰好处理一次是最严格的保证，也是最难实现的。恰好处理一次语义不仅仅意味着没有事件丢失，还意味着针对每一个数据，内部状态仅仅更新一次。

### 一致性检查点（Checkpoints）
Flink 使用了一种轻量级快照机制 —— [[Flink容错机制|检查点]]（checkpoint）来保证 exactly-once 语义

有状态流应用的一致检查点，其实就是：所有任务的状态，在某个时间点的一份拷贝（一份快照）。而这个时间点，应该是所有任务都恰好处理完一个相同的输入数据的时候。

应用状态的一致检查点，是 Flink 故障恢复机制的核心


### Flink+Kafka 端到端状态一致性的保证
>内部保证 —— checkpoint
>source 端 —— 可重设数据的读取位置
>sink 端 —— 从故障恢复时，数据不会重复写入外部系统

#### 内部保证
利用 checkpoint 机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性

#### Source端
kafka consumer 作为 source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性。

#### Sink端

##### 两阶段提交（2PC）
- 第一条数据来了之后，开启一个 kafka 的事务（transaction），正常写入 kafka 分区日志但标记为未提交，这就是“预提交”
- jobmanager 触发 checkpoint 操作，barrier 从 source 开始向下传递，遇到barrier 的算子将状态存入状态后端，并通知 jobmanager
- sink 连接器收到 barrier，保存当前状态，存入 checkpoint，通知 jobmanager，并开启下一阶段的事务，用于提交下个检查点的数据
- jobmanager 收到所有任务的通知，发出确认信息，表示 checkpoint 完成
- sink 任务收到 jobmanager 的确认信息，正式提交这段时间的数据
- 外部kafka关闭事务，提交的数据可以正常消费了。

###### 具体步骤
- beginTransaction，在开启事务之前，会在目标文件系统的临时目录中**创建一个临时文件**，在处理数据时将数据写入这个文件里面。
- preCommit，在预提交阶段，将内存中缓存的数据**刷写（flush）到文件，然后关闭文件**。还将为属于下一个检查点的任何后续写入启动新事物
- commit，在提交阶段，将预提交写入的临时文件**移动到真正的目标目录中**，这代表着最终的数据会有一些延迟；
- abort，在中止阶段，我们**删除临时文件**。