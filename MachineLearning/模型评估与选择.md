---
aliases: 
date created: April 30th 2023, 3:31:33 pm
date modified: August 2nd 2023, 10:22:05 am
title: 模型评估与选择
---
#input 
#hung 

## 评估方法
### 留出法
将样本随机划分成两个部分——测试部分和训练部分。
一般可能会采用多次随机分割，来减小偏差。

### 交叉验证方法
>软工 3 中的 SentiStrength 项目采用了这个。
#### 定义
k-fold cross validation
将数据集 D 划分为 k 个大小相似的互斥子集。然后，每次用 k-1 个子集的并集作为训练集，余下的那个子集作为测试集; 这样就可获得 k 组训练/ 测试集，从而可进行 k 次训练和测试，最终返回的是这 k 个测试结果的均值。

#### 衍生
##### 多次分割
在分割的时候采用多次分割，例如“10次10折交叉验证”——一共可以训练 100 次。

##### 留一法(Leave-One -Out，简称 LOO )
假设数据集中有 m 个样本，令 k=m。但只适用于数据集较小的模型。

### 自助法
>bootstrapping

给定包含 m 个样本的数据集，每次随机从 D 中挑选一个样本，将其放入 D' 中，并将样本**放回**。共取 m 个。
在数据量足够的情况下不会使用这个方法。

## 性能度量
### 查准率、查全率与 F1
查准率（准确率） **P**:被学习器预测为正例的样例中有多大比例是真正例。
查全率（召回率） **R**:所有正例当中有多大比例被学习器预测为正例。
F1 是查准率和查全率的调和平均数。
$$\frac{1}{F1}  = \frac{1}{P} + \frac{1}{R}$$
### ROC 与 AUC
threshold (阈值)
根据学习器的预测结果对样例对样例进行排序，按此顾序逐个把样本作为正例进行预测，每次计算 出两个重要量的值，分别以它们为横、纵坐标作图。
$TPR = \frac{TP}{TP+FN}$  $FPR=\frac{FP}{TN+FP}$
![image.png](https://typora-tes.oss-cn-shanghai.aliyuncs.com/picgo/20230430164948.png)
![image.png](https://typora-tes.oss-cn-shanghai.aliyuncs.com/picgo/20230430165302.png)
>AUC 是面积

### 代价敏感错误率


## 比较检验